import logging

from overrides import overrides
from argparse import _SubParsersAction
from typing import Dict

from ssdn.cli.cmds import Command
from ssdn.eval import DenoiserEvaluator
from ssdn.cfg import DEFAULT_RUN_DIR
from ssdn.params import ConfigValue

logger = logging.getLogger(__name__)


class EvaluateCommand(Command):
    @overrides
    def configure(self, parser: _SubParsersAction):
        cmd_parser = parser.add_parser(self.cmd(), help="Evaluate a pre-trained model.")
        cmd_parser.add_argument(
            "--model",
            "-m",
            required=True,
            help="Path to model weights or training file.",
        )
        cmd_parser.add_argument(
            "--dataset",
            "-d",
            required=True,
            help="Path to either a hdf5 file generated by 'dataset_tool_h5.py' or a folder of images.",
        )
        cmd_parser.add_argument(
            "--runs_dir",
            default=DEFAULT_RUN_DIR,
            help="Directory in which the output directory is generated."
        )
        cmd_parser.add_argument(
            "--batch_size",
            type=int,
            help="Batch size to use, will default to that used while training.",
        )

    @overrides
    def execute(self, args: Dict):
        evaluator = DenoiserEvaluator(args["model"], runs_dir=args["runs_dir"])
        if args.get("batch_size", None) is not None:
            evaluator.cfg[ConfigValue.TEST_MINIBATCH_SIZE] = args["batch_size"]
        evaluator.set_test_data(args["dataset"])
        evaluator.evaluate()

    @overrides
    def cmd(self) -> str:
        return "eval"
