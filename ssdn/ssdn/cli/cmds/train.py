import logging
import ssdn

from overrides import overrides
from argparse import _SubParsersAction
from typing import Dict

from ssdn.cli.cmds import Command
from ssdn.params import NoiseAlgorithm, NoiseValue, ConfigValue
from ssdn.train import resume_run, DenoiserTrainer
from ssdn.cfg import DEFAULT_RUN_DIR

logger = logging.getLogger(__name__)


class TrainCommand(Command):

    START_CMD = "start"
    RESUME_CMD = "resume"

    @overrides
    def configure(self, parser: _SubParsersAction):
        cmd_parser = parser.add_parser(
            self.cmd(), help="Train or resume training of a Denosier model. "
        )
        # Split behaviour into start and resume
        action_parsers = cmd_parser.add_subparsers(dest="train_cmd", required=True)
        start_parser = action_parsers.add_parser(
            TrainCommand.START_CMD, help="start command help"
        )
        self.add_shared_args(start_parser, True)
        start_parser.add_argument(
            "--algorithm",
            "-a",
            required=True,
            help="The algorithm to train.",
            choices=[c.value for c in ssdn.utils.list_constants(NoiseAlgorithm)],
        )
        start_parser.add_argument(
            "--noise_style",
            "-n",
            required=True,
            help="Noise style using a string configuration in the format: {noise_type}{args} "
            + "where {args} are the arguments passed to the noise function. The formats for the "
            + "supported noise types include 'gauss{SD}', 'gauss{MIN_SD}_{MAX_SD}', 'poisson{LAMBDA}' "
            + "'poisson{MIN_LAMBDA}_{MAX_LAMBDA}'. If parameters contain a decimal point they are "
            + "treated as floats. This means the underlying noise adding method will not attempt to "
            + "scale them (/ 255). By default noise algorithms will use truncated versions (clipped "
            + "prior to training) -  Append '_nc' to avoid this.",
        )
        start_parser.add_argument(
            "--noise_value",
            help="[SSDN] Whether the noise value should be estimated.",
            choices=[c.value for c in ssdn.utils.list_constants(NoiseValue)],
        )
        start_parser.add_argument(
            "--mono",
            action="store_true",
            help="Convert input data to greyscale (single channel).",
        )
        start_parser.add_argument(
            "--diagonal",
            action="store_true",
            help="[SSDN] Enforce a diagonal covariance matrix.",
        )

        start_parser.add_argument(
            "--runs_dir",
            default=DEFAULT_RUN_DIR,
            help="Directory in which the output directory is generated."
        )

        resume_parser = action_parsers.add_parser(
            TrainCommand.RESUME_CMD,
            help="Resume the training of a model. Note that configuration arguments "
            + "used on start are valid when resuming but may cause undefined behaviour - "
            + "use these for redefining data locations if needed.",
        )
        resume_parser.add_argument(
            "run_dir",
            help="Path to run directory to resume, the latest *.training file will be used.",
        )

        self.add_shared_args(resume_parser, False)

    def add_shared_args(self, parser: _SubParsersAction, start: bool):
        parser.add_argument(
            "--train_dataset",
            "-t",
            required=start,
            help="Path to training dataset. This can be either a hdf5 file generated by "
            + "'dataset_tool_h5.py' or a folder of images. Note that images smaller than "
            + "the patch size will be padded using reflection when a folder is used.",
        )
        parser.add_argument(
            "--validation_dataset",
            "-v",
            help="Path to validation dataset. This can be either a hdf5 file generated by "
            + "'dataset_tool_h5.py' or a folder of images.",
        )

        parser.add_argument(
            "--iterations",
            "-i",
            required=start,
            type=int,
            help="Number of iterations (input images) to train for.",
        )
        parser.add_argument(
            "--eval_interval",
            type=int,
            help="Number of iterations between evaluations. Should be divisible by "
            + "training batch size.",
        )
        parser.add_argument(
            "--checkpoint_interval",
            type=int,
            help="Number of iterations between saving checkpoints. Should be divisible by "
            + "training batch size.",
        )
        parser.add_argument(
            "--print_interval",
            type=int,
            help="Number of iterations between printing ongoing results to command line and "
            + "Tensorboard, should be divisible by training batch size.",
        )
        parser.add_argument(
            "--train_batch_size",
            type=int,
            help="Batch size to use for training images.",
        )
        parser.add_argument(
            "--validation_batch_size",
            type=int,
            help="Batch size to use for validation images.",
        )
        parser.add_argument(
            "--patch_size", type=int, help="Patch size to use for training (square).",
        )

    @overrides
    def execute(self, args: Dict):
        if args["train_cmd"] == "start":
            if args["algorithm"] == "ssdn" and "noise_value" not in args:
                args["PARSER"].error("SSDN requires --noise_value")
            cfg = ssdn.cfg.base()
            if args.get("algorithm", None) is not None:
                cfg[ConfigValue.ALGORITHM] = NoiseAlgorithm(args["algorithm"])
            if args.get("noise_style", None) is not None:
                cfg[ConfigValue.NOISE_STYLE] = args["noise_style"]
            if cfg.get("noise_value", None) is not None:
                cfg[ConfigValue.NOISE_VALUE] = NoiseValue(args["noise_value"])
            if args.get("mono", None) is not None:
                cfg[ConfigValue.IMAGE_CHANNELS] = 1
            if args.get("diagonal", None) is not None:
                cfg[ConfigValue.TRAIN_ITERATIONS] = args["diagonal"]
            trainer = DenoiserTrainer(cfg, runs_dir=args["runs_dir"])
        elif args["train_cmd"] == "resume":
            trainer = resume_run(args["run_dir"])
        else:
            raise NotImplementedError("Invalid train command")

        # Handle shared args
        if args.get("train_dataset", None) is not None:
            trainer.set_train_data(args["train_dataset"])
        if args.get("validation_dataset", None) is not None:
            trainer.set_test_data(args["validation_dataset"])
        if args.get("iterations", None) is not None:
            cfg[ConfigValue.TRAIN_ITERATIONS] = args["iterations"]
        if args.get("eval_interval", None) is not None:
            cfg[ConfigValue.EVAL_INTERVAL] = args["eval_interval"]
        if args.get("checkpoint_interval", None) is not None:
            cfg[ConfigValue.SNAPSHOT_INTERVAL] = args["checkpoint_interval"]
        if args.get("print_interval", None) is not None:
            cfg[ConfigValue.PRINT_INTERVAL] = args["print_interval"]
        if args.get("train_batch_size", None) is not None:
            cfg[ConfigValue.TRAIN_MINIBATCH_SIZE] = args["train_batch_size"]
        if args.get("validation_batch_size", None) is not None:
            cfg[ConfigValue.TEST_MINIBATCH_SIZE] = args["validation_batch_size"]
        if args.get("patch_size", None) is not None:
            cfg[ConfigValue.TRAIN_PATCH_SIZE] = args["patch_size"]

        # Start the training
        trainer.train()

    @overrides
    def cmd(self) -> str:
        return "train"
